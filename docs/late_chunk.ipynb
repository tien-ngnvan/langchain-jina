{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LateChunkQdrant\n",
    "\n",
    "Based on the [Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding Models](https://arxiv.org/abs/2409.04701) paper.\n",
    "\n",
    "This notebooks explains how apply `LateChunkEmbeddings` and `LatechunkQdrant` vectorstore.\n",
    "\n",
    "**Notes:**\n",
    "- The key idea behind Late Chunking is to first embed the entire text, then split it into chunks later. To implement Late Chunking in Langchain, we use `LateChunkQdrant` vectorstore that applies the late chunking technique.\n",
    "\n",
    "- Can combine with any `text_splitting` used in LangChain or you can custom with the [Chunk](https://github.com/jina-ai/late-chunking/blob/main/chunked_pooling/chunking.py) used in the paper. We'll give the example with handle the same method of authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-jina qdrant-client beautifulsoup4 transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "To access Jina embedding models you'll need to go https://jina.ai/embeddings/ get an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if not os.getenv(\"JINA_API_KEY\"):\n",
    "    os.environ[\"JINA_API_KEY\"] = getpass.getpass(\"Enter your key: \") # \"jina_*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "import EmbeddingTabs from \"@theme/EmbeddingTabs\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_jina import LateChunkEmbeddings\n",
    "\n",
    "text_embeddings = LateChunkEmbeddings(\n",
    "    jina_api_key=os.environ.get(\"JINA_API_KEY\"),\n",
    "    model_name=\"jina-embeddings-v3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purpose, we need to ensure the input text fits within the model’s context length. Therefore, we will use the tokenizer from Hugging Face check input tokenized length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Latechunk process, we need to ensure that the entire text being embedded fits within the model's context length limit (8192 tokens). Therefore, we load the `tokenizer` from the `transformers` library to handle and validate the input length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('jinaai/jina-embeddings-v3')\n",
    "\n",
    "text_splitter.tokenizer = tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LateChunkQdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config several parameters use in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ROOT = \"qdrantDB\"\n",
    "    CLT_NAME = \"demo\"\n",
    "    TOPK = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create LateChunkQdrant database. We set the return documents with 5 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Create new collection: demo ======\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.docstore.document import Document\n",
    "from langchain_jina import LateChunkQdrant\n",
    "\n",
    "\n",
    "client = QdrantClient()\n",
    "\n",
    "vectorstore = LateChunkQdrant(\n",
    "    client, \n",
    "    collection_name=Config.CLT_NAME,\n",
    "    embeddings=text_embeddings, \n",
    "    text_splitter=text_splitter\n",
    ")\n",
    "\n",
    "if os.path.isdir(os.path.join(Config.ROOT, \"collection\", Config.CLT_NAME)):\n",
    "    print(f\"===== Load exits collection: {Config.CLT_NAME} ======\")\n",
    "    vectorstore = vectorstore.from_existing_collection(\n",
    "        embedding=text_embeddings, \n",
    "        path=Config.ROOT,\n",
    "        collection_name=Config.COLLECTION_NAME, \n",
    "        text_splitter=text_splitter\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(f\"===== Create new collection: {Config.CLT_NAME} ======\")\n",
    "    with open(\"state_of_the_union.txt\") as f:\n",
    "        state_of_the_union = f.read()\n",
    "\n",
    "    documents  = [\n",
    "        Document(\n",
    "            page_content=state_of_the_union, \n",
    "            metadata={\"source\": \"state_of_the_union.txt\"}\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    vectorstore = vectorstore.from_documents(\n",
    "        documents=documents, \n",
    "        embedding=text_embeddings, \n",
    "        text_splitter=text_splitter,\n",
    "        path=Config.ROOT, \n",
    "        collection_name=Config.CLT_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query vector store\n",
    "\n",
    "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent.\n",
    "\n",
    "### Query directly\n",
    "\n",
    "#### Similarity search\n",
    "Performing a simple similarity search can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. [{'source': 'state_of_the_union.txt', '_id': 'fe9823ebb87b47839c39c93781a3fffe', '_collection_name': 'demo'}]\n",
      "* And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. [{'source': 'state_of_the_union.txt', '_id': 'f3c77ec9d0fe44cbb953bde75ae586bb', '_collection_name': 'demo'}]\n",
      "* As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. [{'source': 'state_of_the_union.txt', '_id': 'b213772f1bc74d12a099a62a2d04aa63', '_collection_name': 'demo'}]\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore.similarity_search(\n",
    "    \"What did the president say about ketanji brown jackson?\",\n",
    "    k=3,\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity search with score\n",
    "\n",
    "If you want to execute a similarity search and receive the corresponding scores you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.289770] One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. [{'source': 'state_of_the_union.txt', '_id': 'fe9823ebb87b47839c39c93781a3fffe', '_collection_name': 'demo'}]\n",
      "* [SIM=0.287874] And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. [{'source': 'state_of_the_union.txt', '_id': 'f3c77ec9d0fe44cbb953bde75ae586bb', '_collection_name': 'demo'}]\n",
      "* [SIM=0.272244] As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. [{'source': 'state_of_the_union.txt', '_id': 'b213772f1bc74d12a099a62a2d04aa63', '_collection_name': 'demo'}]\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore.similarity_search_with_score(\n",
    "    \"what did the president say about ketanji brown jackson?\", \n",
    "    k=3\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search by vector\n",
    "\n",
    "You can also search by vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* First, stay protected with vaccines and treatments. We know how incredibly effective vaccines are. If you’re vaccinated and boosted you have the highest degree of protection. [{'source': 'state_of_the_union.txt', '_id': '3b89fdcd5f134708819d4c7581cfc122', '_collection_name': 'demo'}]\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore.similarity_search_by_vector(\n",
    "    embedding=text_embeddings.embed_query(\"Protect Americans from COVID-19\"),\n",
    "    k=1\n",
    ")\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by turning into retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'state_of_the_union.txt', '_id': 'fe9823ebb87b47839c39c93781a3fffe', '_collection_name': 'demo'}, page_content='One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.'),\n",
       " Document(metadata={'source': 'state_of_the_union.txt', '_id': 'f3c77ec9d0fe44cbb953bde75ae586bb', '_collection_name': 'demo'}, page_content='And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.'),\n",
       " Document(metadata={'source': 'state_of_the_union.txt', '_id': 'b213772f1bc74d12a099a62a2d04aa63', '_collection_name': 'demo'}, page_content='As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential.'),\n",
       " Document(metadata={'source': 'state_of_the_union.txt', '_id': 'a699784c02124b2381cd528e31e3752a', '_collection_name': 'demo'}, page_content='Revise our laws so businesses have the workers they need and families don’t wait decades to reunite. \\n\\nIt’s not only the right thing to do—it’s the economically smart thing to do.'),\n",
       " Document(metadata={'source': 'state_of_the_union.txt', '_id': '67dc5b868a7340b2ade5eb9ab028bcdb', '_collection_name': 'demo'}, page_content='We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": Config.TOPK}\n",
    ")\n",
    "retriever.invoke(\"What did the president say about ketanji brown jackson?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage for retrieval-augmented generation\n",
    "\n",
    "For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n",
    "\n",
    "- [Tutorials](/docs/tutorials/)\n",
    "- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\n",
    "- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `LatecChunkQdrant` vector store features and configurations head to the API reference: https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Qdrant.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips\n",
    "- The LateChunking approach is used to solve the problem of text segments losing meaning due to missing context. It is particularly effective with coherent documents, where each part is related to the whole.\n",
    "\n",
    "- For very long documents, not all of the context may be required. Therefore, when the text is divided into chapters or larger sections, enough context is provided for the embedding model to process all tokens accurately.\n",
    "  \n",
    "- For multiple documents (hundreds of pages), the LateChunkQdrant automatically splits them into smaller batches, making the processing more manageable and optimized for hardware."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
